{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hd5",
      "provenance": [],
      "authorship_tag": "ABX9TyMm0P2+QWkTWg4KMyCVOej+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/merazlab/python/blob/master/hd5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99-LQy_2t2Vd",
        "colab_type": "text"
      },
      "source": [
        "#HDF5- Hierachical Data Formats\n",
        "\n",
        "it support large complex hetrogenious data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WeRdAvudvsAd",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://www.neonscience.org/sites/default/files/images/HDF5/hdf5_structure4.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjHwLIncwEze",
        "colab_type": "text"
      },
      "source": [
        "HDF5 file format is self describing. it means each file or group and dataset can have associated with metadata. that metadata desccribe what the data are."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSTkSXSQxCVy",
        "colab_type": "text"
      },
      "source": [
        "##Saving and reading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpvCunEFsqxT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import h5py\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmMOZ8vmxMQF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "c769910d-b3e5-4729-ff12-5d7642aa313c"
      },
      "source": [
        "arr1 = np.random.randint(1, 4, (2, 3))\n",
        "arr2 = np.random.randint(1, 4, (1, 2))\n",
        "print(arr1)\n",
        "print(arr2)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2 3 1]\n",
            " [1 2 2]]\n",
            "[[2 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLB5ptUjm0UX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with h5py.File('mynewh5.hdf5', 'w') as f:\n",
        "  f.create_dataset(\"dataset1\", data = arr1)\n",
        "  f.create_dataset(\"dataset2\", data = arr2)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0X9XmLFuyaiH",
        "colab_type": "text"
      },
      "source": [
        "##Reading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBoSuZOIx_Ld",
        "colab_type": "code",
        "outputId": "39c3c634-1dae-4a05-898f-b1a87ef6199f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "with h5py.File('mynewh5.hdf5', 'r') as h5:\n",
        "  print(h5.keys())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<KeysViewHDF5 ['dataset1', 'dataset2']>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_1aEDQBz6CU",
        "colab_type": "text"
      },
      "source": [
        "Find which datasets are in hdf file  use below method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4cpdz_zy7cs",
        "colab_type": "code",
        "outputId": "129f7438-cfc7-4bc5-a33e-567889bc5eeb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "with h5py.File('mynewh5.hdf5', 'r') as hdf:\n",
        "  data = hdf.get(\"dataset1\")\n",
        "  print(type(data))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'h5py._hl.dataset.Dataset'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kev7dz-wnYm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "0fd477d0-9ef2-4d71-87ce-b6391849dc5d"
      },
      "source": [
        "with h5py.File('mynewh5.hdf5', 'r') as hdf:\n",
        "  data_h5 = hdf.get(\"dataset1\")\n",
        "  data = np.array(data_h5)\n",
        "  print(data)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2 3 1]\n",
            " [1 2 2]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7E9lLMsxVpM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "09f6ef2a-ceae-4824-d4ca-c7aa1ef1b004"
      },
      "source": [
        "f =  h5py.File('mynewh5.hdf5', 'r')\n",
        "data_h5 = f.get(\"dataset1\")\n",
        "data = np.array(data_h5)\n",
        "print(data)\n",
        "f.close()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2 3 1]\n",
            " [1 2 2]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZQgoUHB0eOz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f = h5py.File('mynewh5.hdf5', 'r')\n",
        "data_h5 = f['dataset1']\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtEGur7Uy8yd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "12d64a8c-c6cd-4f51-aa82-38078fcd3c91"
      },
      "source": [
        "print(data_h5.dtype)\n",
        "f.close()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5fWQDOw0ScV",
        "colab_type": "text"
      },
      "source": [
        "##Group"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcVzz7QP2_L3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "arr1 = np.random.randint(1, 4, (2, 3))\n",
        "arr2 = np.random.randint(1, 4, (1, 2))\n",
        "arr3 = np.random.randint(1, 4, (5))\n",
        "arr4 = np.random.randint(1, 4, (3, 2, 2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kus8S00G0lC7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with h5py.File(\"myh5file.hdf5\", \"w\") as hdf:\n",
        "  g1 = hdf.create_group(\"group1\")\n",
        "  g1.create_dataset(\"darr1\", data = arr1)\n",
        "  g1.create_dataset(\"darr2\", data = arr2)\n",
        "\n",
        "  g2 = hdf.create_group(\"group2/subgroup1\")\n",
        "  g2.create_dataset(\"darr3\", data = arr3)\n",
        "  g2.create_dataset(\"darr4\", data = arr4)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJSyxP252lvT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "be3696c0-3710-445a-e669-6e6c38ebf745"
      },
      "source": [
        "with h5py.File(\"myh5file.hdf5\", \"r\") as f:\n",
        "  print(f.items())\n",
        "  print(list(f.items()))\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ItemsViewHDF5(<HDF5 file \"myh5file.hdf5\" (mode r)>)\n",
            "[('group1', <HDF5 group \"/group1\" (2 members)>), ('group2', <HDF5 group \"/group2\" (1 members)>)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9652d1ys56vt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5a3116b0-dc3e-48d8-eaef-a03356db2e58"
      },
      "source": [
        "with h5py.File(\"myh5file.hdf5\", \"r\") as f:\n",
        "  data_h5 = f.get(\"group1\")\n",
        "  data = list(data_h5.items())\n",
        "  print(data)\n",
        "  "
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('darr1', <HDF5 dataset \"darr1\": shape (2, 3), type \"<i8\">), ('darr2', <HDF5 dataset \"darr2\": shape (1, 2), type \"<i8\">)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFTnXXzf7V-V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e9d80d25-5873-4bd9-a45e-1b0449e9af30"
      },
      "source": [
        "with h5py.File(\"myh5file.hdf5\", \"r\") as f:\n",
        "  data_g1 = f.get(\"group1\")\n",
        "  a2 = np.array(data_g1.get(\"darr2\"))\n",
        "  print(a2)\n",
        "  "
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[3 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCpJrs_J8syJ",
        "colab_type": "text"
      },
      "source": [
        "##Compression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBQy_ot6-cnT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with h5py.File(\"compressfile\", \"w\") as hdf:\n",
        "  hdf.create_dataset(\"data1\", data = arr1, compression='gzip')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}